{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering drills\n",
    "\n",
    "Welcome, traveler, you have arrived in the drills section of the clustering chapter. Here, you can practice some clustering techniques.\n",
    "\n",
    "If you have not checked out the intro notebook, I advise you do so. We will use the same [Pokémon](./assets/pokemon.csv) dataset to further our journey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multi-dimensional data\n",
    "\n",
    "In the example, we wanted to determine the **most physically diverse** [Pokémon](./assets/pokemon.csv) team there is. To do so, we clustered the Pokémon into groups according to their **weight** and **height** using **k-means**.\n",
    "\n",
    "Is this really the most diverse team out there though? The Pokémon selected there are still similar in terms of **combat abilities**, and we have this data available.\n",
    "\n",
    "For the first drill, I want you to:\n",
    "   - cluster the Pokémon into 6 groups according to similar:\n",
    "       - height\n",
    "       - weight\n",
    "       - hp\n",
    "       - attack\n",
    "       - defense\n",
    "       - speed\n",
    "   - visualize these multidimensional clusters using a scatter plot matrix\n",
    "   - determine the most dissimilar Pokémon team from these clusters\n",
    "   \n",
    "So that you have **6-dimensional** clusters containing **diverse** Pokémon groups from which you can determine your Pokémon team similar to the method described in the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster your Pokémon here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise your clusters here (take a look at the pandas scatter_matrix or seaborn's pairplot method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine your final Pokémon here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Similarity criteria\n",
    "\n",
    "Very nice! What a unique team!\n",
    "\n",
    "You probably used the same **similarity criteria** as the introduction example. **k-means** uses Euclidean distance as a similarity criteria, so it makes sense that we also use Euclidean distance for our **dissimilarity criteria**, but what would happen if we picked something else?\n",
    "\n",
    "\"Woah, you're going too fast, 'Euclidean distance'? What do you mean by that?\"\n",
    "\n",
    "This is distance as we know it in the **real world**, a line connecting two points. But distance does not have to be defined this way in our **problem space**, it can be **Manhattan distance**, or **squared distance**, or something else entirely.\n",
    "\n",
    "<img src=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-981-10-8818-6_7/MediaObjects/463464_1_En_7_Fig2_HTML.jpg\" align=\"center\" width=\"600\"/>\n",
    "\n",
    "Replacing this similarity criteria for the `sklearn` k-means is no trivial task, so I will not ask this of you, but changing it for our **dissimilarity criteria** should be doable.\n",
    "\n",
    "For the next exercise, I would like you to:\n",
    "- replace the dissimilarity criteria from the example by:\n",
    "    - Manhattan distance\n",
    "    - Squared distance\n",
    "    - 1/(Squared distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign dissimilarity to your Pokémon here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did your team change? Why do you think it did(n't)? Discuss this with one of your colleagues!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Heterogenous data\n",
    "\n",
    "There! We did it! The most **diverse Pokémon team** possible...or is it?\n",
    "\n",
    "We have clustered our Pokémon according to **weight** and **height** in the example, and according to **combat abilities** in the first drill, but what about **Pokémon type**?\n",
    "\n",
    "Some of the chosen Pokémon may have the same type, as this data was ignored during clustering? But to get a really diverse team, we should take these into account!\n",
    "\n",
    "For this drill I want you to:\n",
    "- cluster the Pokémon into 6 groups according to similar:\n",
    "    - weight\n",
    "    - height\n",
    "    - primary Pokémon type\n",
    "    - secondary Pokémon type\n",
    "- determine the most dissimilar Pokémon team from these clusters\n",
    "\n",
    "But wait, these Pokémon types, they're in **text format**, how do you compare these to the **numerical data**? It's time to **vectorize** this data. **Vectorizing** this textual data means representing this data in a way that can be understood by machine learning algorithms. \n",
    "\n",
    "For example, let's say there are only 3 Pokémon types, and Pokémon can only have one type. Vectorizing a **grass**, **fire**, and **water** Pokémon would look like this:\n",
    "- grass -> [1, 0, 0]\n",
    "- fire  -> [0, 1, 0]\n",
    "- water -> [0, 0, 1]\n",
    "\n",
    "So in this case, **3-dimensional** data. In our case though, we have a weight dimension, a height dimension, 18 primary and secondary dimensions, so a whopping **38 dimensions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize your Pokémon type data here (there are modules that vectorize data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster your multi-dimensional Pokémon data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine your unique team here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But wait, did you properly **normalize** your data? If you simply vectorize your data like in the example shown above, you might not get the results you want (try this for yourselves, what do you notice?).\n",
    "\n",
    "The example normalizes its data using the **z-score**. What does this mean? Z-score or mean normalization means we are using our **problem space** where our data lives optimally. \n",
    "\n",
    "In the case of the Pokémon weight and height, it was clear to see the **order of magnitude** of the weight is larger than that of the height. During clustering, this would mean that **weight similarity would matter more than height similarity**, since the Euclidean distance between points of data would be larger.\n",
    "\n",
    "For example, a Pokémon weighing 200kg and measuring 4m is about **as similar** as another Pokémon weighing 100kg and measuring 2m in terms of both weight and height. But the euclidian difference in between the weight difference is 100(kg), while the difference of height is only 2(m). That is where normalization comes in handy. It scales these metrics so they can be compared fairly.\n",
    "\n",
    "Which is why when we vectorize out **Pokémon types** into vectors of length one, the **Euclidean distance** between one Pokémon type and the other is about 1.4 (thanks Pythagoras), which isn't that much compared to the weight and height difference.\n",
    "\n",
    "Show me how you would **make sure** that **similarity or dissimilarity** of the **Pokémon type** matters more than **weight or height**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize and scale your data in such a way that Pokémon type similarity matters more than the other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cluster method comparison\n",
    "\n",
    "I hope you're getting a bit more comfortable with the **k-means** method, it sure is a popular one, but it's [not the only clustering technique](https://scikit-learn.org/stable/modules/clustering.html) out there!\n",
    "\n",
    "For this exercise, I want you to:\n",
    "- pick 3 clustering techniques from the `scikit-learn` library\n",
    "- cluster the Pokémon according weight and height\n",
    "- try to adjust the cluster method arguments so 6 clusters are obtained after clustering\n",
    "- evaluate in-cluster similarity and cluster-to-cluster similarity:\n",
    "  - compare every Pokémon in a cluster to every other Pokémon within that same cluster (choose your own similarity criteria)\n",
    "  - take the average of these in-cluster similarities\n",
    "  - do this for every cluster\n",
    "  - take the the average or centroid of ever cluster, and determine the similarity to every other cluster\n",
    "  - compare these two metrics (in-cluster similarity and cluster-to-cluster similarity) for every chosen clustering technique\n",
    "  - determine the 'best' technique by maximizing in-cluster similarity and minimizing cluster-to-cluster similarity\n",
    "- visualize the results\n",
    "\n",
    "Bonus: track these metrics for every iteration of the algorithms and plot the progression from start to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare your techniques here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
